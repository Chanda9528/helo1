{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C80sX5YuXHUi"
   },
   "source": [
    "\n",
    "\n",
    "> **Load imdb datasets:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "print(len(train_data), len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip1XISClXT4V"
   },
   "source": [
    "**Preprocess text data using tokenization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XreIV9z4XliV"
   },
   "source": [
    "**Vocabulary Creation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 20002\n",
      " word2idx.pkl saved successfully\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}\n",
    "\n",
    "for item in train_data:\n",
    "    for word in tokenize(item[\"text\"]):\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "vocab = sorted(word_freq, key=word_freq.get, reverse=True)[:MAX_VOCAB_SIZE]\n",
    "\n",
    "word2idx = {word: idx + 2 for idx, word in enumerate(vocab)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "print(\"Vocab Size:\", vocab_size)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"word2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n",
    "\n",
    "print(\" word2idx.pkl saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUSgNZtWXqzU"
   },
   "source": [
    "**Padding and truncation to fixed length:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "MAX_LEN = 150\n",
    "\n",
    "def encode(text):\n",
    "    tokens = tokenize(text)\n",
    "    encoded = [word2idx.get(word, 1) for word in tokens]\n",
    "    return torch.tensor(encoded[:MAX_LEN])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d41xmZThX4GW"
   },
   "source": [
    "**Prepare data for model input:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.texts = [encode(item[\"text\"]) for item in data]\n",
    "        self.labels = [item[\"label\"] for item in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    return texts, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQOjFQfzYClb"
   },
   "source": [
    "**Dataloader**:Train-test split handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    IMDbDataset(train_data),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    IMDbDataset(test_data),\n",
    "    batch_size=32,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Moltl89Yhzh"
   },
   "source": [
    "**Build a custom LSTM model in PyTorch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return self.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvp-59s1Y2pr"
   },
   "source": [
    "**Training Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (embedding): Embedding(20002, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = SentimentLSTM(vocab_size, 128, 128)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbEYw-fOZNwr"
   },
   "source": [
    "**Train custom LSTM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 541.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 536.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 467.41\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for texts, labels in train_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3FEh29KZYXx"
   },
   "source": [
    "**Evaluation Metrics:** Evaluate both models using identical metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7396\n",
      "Precision: 0.7708446373666125\n",
      "Recall: 0.68192\n",
      "F1: 0.7236607521860939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "preds, true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = model(texts).squeeze()\n",
    "        preds.extend((outputs > 0.5).int().tolist())\n",
    "        true.extend(labels.tolist())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(true, preds))\n",
    "print(\"Precision:\", precision_score(true, preds))\n",
    "print(\"Recall:\", recall_score(true, preds))\n",
    "print(\"F1:\", f1_score(true, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"custom_lstm_sentiment.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
